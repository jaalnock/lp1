{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        antecedents     consequents  antecedent support  consequent support  \\\n",
      "0            (eggs)       (burgers)            0.179709            0.087188   \n",
      "1         (burgers)          (eggs)            0.087188            0.179709   \n",
      "2    (french fries)       (burgers)            0.170911            0.087188   \n",
      "3         (burgers)  (french fries)            0.087188            0.170911   \n",
      "4   (mineral water)       (burgers)            0.238368            0.087188   \n",
      "..              ...             ...                 ...                 ...   \n",
      "95      (spaghetti)      (pancakes)            0.174110            0.095054   \n",
      "96         (shrimp)     (spaghetti)            0.071457            0.174110   \n",
      "97      (spaghetti)        (shrimp)            0.174110            0.071457   \n",
      "98       (tomatoes)     (spaghetti)            0.068391            0.174110   \n",
      "99      (spaghetti)      (tomatoes)            0.174110            0.068391   \n",
      "\n",
      "     support  confidence      lift  representativity  leverage  conviction  \\\n",
      "0   0.028796    0.160237  1.837830               1.0  0.013128    1.086988   \n",
      "1   0.028796    0.330275  1.837830               1.0  0.013128    1.224818   \n",
      "2   0.021997    0.128705  1.476173               1.0  0.007096    1.047650   \n",
      "3   0.021997    0.252294  1.476173               1.0  0.007096    1.108844   \n",
      "4   0.024397    0.102349  1.173883               1.0  0.003614    1.016889   \n",
      "..       ...         ...       ...               ...       ...         ...   \n",
      "95  0.025197    0.144717  1.522468               1.0  0.008647    1.058066   \n",
      "96  0.021197    0.296642  1.703760               1.0  0.008756    1.174209   \n",
      "97  0.021197    0.121746  1.703760               1.0  0.008756    1.057260   \n",
      "98  0.020931    0.306043  1.757755               1.0  0.009023    1.190117   \n",
      "99  0.020931    0.120214  1.757755               1.0  0.009023    1.058905   \n",
      "\n",
      "    zhangs_metric   jaccard  certainty  kulczynski  \n",
      "0        0.555754  0.120941   0.080026    0.245256  \n",
      "1        0.499424  0.120941   0.183552    0.245256  \n",
      "2        0.389069  0.093168   0.045482    0.190499  \n",
      "3        0.353384  0.093168   0.098160    0.190499  \n",
      "4        0.194486  0.081009   0.016609    0.191083  \n",
      "..            ...       ...        ...         ...  \n",
      "95       0.415518  0.103279   0.054879    0.204897  \n",
      "96       0.444850  0.094474   0.148363    0.209194  \n",
      "97       0.500143  0.094474   0.054159    0.209194  \n",
      "98       0.462740  0.094465   0.159746    0.213129  \n",
      "99       0.521973  0.094465   0.055628    0.213129  \n",
      "\n",
      "[100 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Step 1: Data Preprocessing\n",
    "# Load the dataset\n",
    "data_path = \"./Datasets/Order2.csv\"  # Replace with the correct path to your dataset\n",
    "transactions = pd.read_csv(data_path, header=None)\n",
    "\n",
    "# Data cleaning: Remove NaN or any non-item entries from each transaction\n",
    "# Convert the entire DataFrame to a list of transactions\n",
    "transactions = transactions.apply(lambda row: [str(item) for item in row if str(item) != 'nan'], axis=1).tolist()\n",
    "\n",
    "# Step 2: Prepare the data for the Apriori algorithm\n",
    "# Convert transactions into a one-hot encoded format\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Step 3: Apply Apriori Algorithm\n",
    "# Set minimum support to find frequent itemsets (example: 0.02)\n",
    "frequent_itemsets = apriori(df, min_support=0.02, use_colnames=True)\n",
    "\n",
    "# Step 4: Apply Association Rules (example: min_threshold=0.7)\n",
    "# Include the `num_itemsets` argument (set to None to not limit)\n",
    "# Remove or add num_itemsets according to version of mlxtend\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=0.7, num_itemsets=None)\n",
    "\n",
    "# Step 5: Visualize the results\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
